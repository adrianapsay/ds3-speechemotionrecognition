{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a0f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch\n",
    "import pandas as pd\n",
    "import torchaudio \n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e28efcc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>version</th>\n",
       "      <th>file name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1012</td>\n",
       "      <td>ANG</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1012_ITH_ANG_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1010</td>\n",
       "      <td>HAP</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1010_IWW_HAP_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1059</td>\n",
       "      <td>FEA</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1059_TAI_FEA_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1090</td>\n",
       "      <td>HAP</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1090_IWL_HAP_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1015</td>\n",
       "      <td>NEU</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1015_TAI_NEU_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7437</th>\n",
       "      <td>1051</td>\n",
       "      <td>HAP</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1051_TAI_HAP_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7438</th>\n",
       "      <td>1010</td>\n",
       "      <td>SAD</td>\n",
       "      <td>MD.wav</td>\n",
       "      <td>1010_IEO_SAD_MD.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7439</th>\n",
       "      <td>1007</td>\n",
       "      <td>SAD</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1007_TAI_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7440</th>\n",
       "      <td>1044</td>\n",
       "      <td>ANG</td>\n",
       "      <td>HI.wav</td>\n",
       "      <td>1044_IEO_ANG_HI.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7441</th>\n",
       "      <td>1019</td>\n",
       "      <td>SAD</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1019_TAI_SAD_XX.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7442 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id emotion version            file name\n",
       "0     1012     ANG  XX.wav  1012_ITH_ANG_XX.wav\n",
       "1     1010     HAP  XX.wav  1010_IWW_HAP_XX.wav\n",
       "2     1059     FEA  XX.wav  1059_TAI_FEA_XX.wav\n",
       "3     1090     HAP  XX.wav  1090_IWL_HAP_XX.wav\n",
       "4     1015     NEU  XX.wav  1015_TAI_NEU_XX.wav\n",
       "...    ...     ...     ...                  ...\n",
       "7437  1051     HAP  XX.wav  1051_TAI_HAP_XX.wav\n",
       "7438  1010     SAD  MD.wav  1010_IEO_SAD_MD.wav\n",
       "7439  1007     SAD  XX.wav  1007_TAI_SAD_XX.wav\n",
       "7440  1044     ANG  HI.wav  1044_IEO_ANG_HI.wav\n",
       "7441  1019     SAD  XX.wav  1019_TAI_SAD_XX.wav\n",
       "\n",
       "[7442 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wav_files = os.listdir('../data/Crema')\n",
    "filename_parts = pd.Series(wav_files).str.split(\"_\")\n",
    "\n",
    "wav_info = pd.DataFrame(filename_parts.tolist(), columns=['id', 'val', 'emotion', 'version']).drop(columns=\"val\")\n",
    "wav_info['file name'] = wav_files\n",
    "\n",
    "wav_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51728f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get wav from Crema\n",
    "\n",
    "# Define the folder containing the .wav files\n",
    "folder_path = '../data/Crema'\n",
    "wav_val = pd.DataFrame({'id': [], 'Sample rate':[],'Waveform shape':[],'Waveform':[]})\n",
    "\n",
    "# Iterate over all files in the folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".wav\"):\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        # Load the .wav file using torchaudio.load()\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        \n",
    "        filename = os.path.basename(file_path)\n",
    "        filename_parts = filename.split(\"_\")\n",
    "        \n",
    "        crema = pd.DataFrame({'id': [filename_parts[0]],'Sample rate': sample_rate, 'Waveform shape': [waveform.shape[0]],'Waveform':[waveform.tolist()]})\n",
    "        \n",
    "        wav_val = pd.concat([wav_val,crema])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eee926b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>emotion</th>\n",
       "      <th>version</th>\n",
       "      <th>file name</th>\n",
       "      <th>Sample rate</th>\n",
       "      <th>Waveform shape</th>\n",
       "      <th>Waveform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1012</td>\n",
       "      <td>ANG</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1012_ITH_ANG_XX.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[-0.000244140625, -0.000335693359375, -0.0014...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1012</td>\n",
       "      <td>ANG</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1012_ITH_ANG_XX.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[-0.005859375, -0.00592041015625, -0.00640869...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1012</td>\n",
       "      <td>ANG</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1012_ITH_ANG_XX.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.0135498046875, 0.013641357421875, 0.013000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1012</td>\n",
       "      <td>ANG</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1012_ITH_ANG_XX.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[-0.006744384765625, -0.0074462890625, -0.008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1012</td>\n",
       "      <td>ANG</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1012_ITH_ANG_XX.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.00238037109375, 0.0032958984375, 0.0018005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608709</th>\n",
       "      <td>1019</td>\n",
       "      <td>SAD</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1019_TAI_SAD_XX.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.00927734375, 0.0084228515625, 0.0088195800...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608710</th>\n",
       "      <td>1019</td>\n",
       "      <td>SAD</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1019_TAI_SAD_XX.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.004852294921875, 0.00616455078125, 0.00653...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608711</th>\n",
       "      <td>1019</td>\n",
       "      <td>SAD</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1019_TAI_SAD_XX.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[0.00146484375, 0.00128173828125, 0.001831054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608712</th>\n",
       "      <td>1019</td>\n",
       "      <td>SAD</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1019_TAI_SAD_XX.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[-0.005035400390625, -0.006103515625, -0.0062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608713</th>\n",
       "      <td>1019</td>\n",
       "      <td>SAD</td>\n",
       "      <td>XX.wav</td>\n",
       "      <td>1019_TAI_SAD_XX.wav</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[[-0.003326416015625, -0.002899169921875, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608714 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id emotion version            file name  Sample rate  \\\n",
       "0       1012     ANG  XX.wav  1012_ITH_ANG_XX.wav      16000.0   \n",
       "1       1012     ANG  XX.wav  1012_ITH_ANG_XX.wav      16000.0   \n",
       "2       1012     ANG  XX.wav  1012_ITH_ANG_XX.wav      16000.0   \n",
       "3       1012     ANG  XX.wav  1012_ITH_ANG_XX.wav      16000.0   \n",
       "4       1012     ANG  XX.wav  1012_ITH_ANG_XX.wav      16000.0   \n",
       "...      ...     ...     ...                  ...          ...   \n",
       "608709  1019     SAD  XX.wav  1019_TAI_SAD_XX.wav      16000.0   \n",
       "608710  1019     SAD  XX.wav  1019_TAI_SAD_XX.wav      16000.0   \n",
       "608711  1019     SAD  XX.wav  1019_TAI_SAD_XX.wav      16000.0   \n",
       "608712  1019     SAD  XX.wav  1019_TAI_SAD_XX.wav      16000.0   \n",
       "608713  1019     SAD  XX.wav  1019_TAI_SAD_XX.wav      16000.0   \n",
       "\n",
       "        Waveform shape                                           Waveform  \n",
       "0                  1.0  [[-0.000244140625, -0.000335693359375, -0.0014...  \n",
       "1                  1.0  [[-0.005859375, -0.00592041015625, -0.00640869...  \n",
       "2                  1.0  [[0.0135498046875, 0.013641357421875, 0.013000...  \n",
       "3                  1.0  [[-0.006744384765625, -0.0074462890625, -0.008...  \n",
       "4                  1.0  [[0.00238037109375, 0.0032958984375, 0.0018005...  \n",
       "...                ...                                                ...  \n",
       "608709             1.0  [[0.00927734375, 0.0084228515625, 0.0088195800...  \n",
       "608710             1.0  [[0.004852294921875, 0.00616455078125, 0.00653...  \n",
       "608711             1.0  [[0.00146484375, 0.00128173828125, 0.001831054...  \n",
       "608712             1.0  [[-0.005035400390625, -0.006103515625, -0.0062...  \n",
       "608713             1.0  [[-0.003326416015625, -0.002899169921875, -0.0...  \n",
       "\n",
       "[608714 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_crema = wav_info.merge(wav_val,right_on = 'id',left_on='id',how='inner')\n",
    "all_crema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b70a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.4734\n",
      "Epoch [2/10], Loss: 1.1031\n",
      "Epoch [3/10], Loss: 1.7263\n",
      "Epoch [4/10], Loss: 1.7336\n",
      "Epoch [5/10], Loss: 2.1317\n",
      "Epoch [6/10], Loss: 1.2658\n",
      "Epoch [7/10], Loss: 1.2770\n",
      "Epoch [8/10], Loss: 1.2077\n",
      "Epoch [9/10], Loss: 1.0831\n",
      "Epoch [10/10], Loss: 1.4223\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1004/1668890742.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Calculate the size of the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mval_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_split\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m# Calculate the size of the training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define a simple linear model\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "# Define input size and output size\n",
    "input_size = 100  # Example input size\n",
    "output_size = 1    # Example output size\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearModel(input_size, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Example loss function (Mean Squared Error)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)  # Example optimizer (Stochastic Gradient Descent)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Assuming inputs and targets are tensors (replace with your actual data)\n",
    "    inputs = torch.randn(32, input_size)  # Example input tensor (batch_size=32)\n",
    "    targets = torch.randn(32, output_size)  # Example target tensor (batch_size=32)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Validation loop\n",
    "# Assuming you have a validation dataset named 'val_loader'\n",
    "# Iterate over validation dataset\n",
    "model.eval()  # Set model to evaluation mode\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Assuming you have a dataset named 'dataset'\n",
    "# dataset should be an instance of a PyTorch Dataset subclass\n",
    "\n",
    "# Define the percentage of data to be used for validation (e.g., 20%)\n",
    "val_split = 0.2\n",
    "\n",
    "# Calculate the size of the validation set\n",
    "val_size = int(val_split * len(dataset))\n",
    "\n",
    "# Calculate the size of the training set\n",
    "train_size = len(dataset) - val_size\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Define batch size for training and validation DataLoaders\n",
    "batch_size = 32  # Adjust as needed\n",
    "\n",
    "# Create DataLoaders for training and validation datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Now you can use train_loader for training and val_loader for validation\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Convert outputs to binary predictions (for binary classification)\n",
    "        predictions = (outputs > 0.5).float()  # Assuming sigmoid activation\n",
    "        \n",
    "        # Append predictions and targets to lists\n",
    "        all_predictions.extend(predictions.numpy().flatten())\n",
    "        all_targets.extend(targets.numpy().flatten())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(all_targets, all_predictions)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "precision = precision_score(all_targets, all_predictions)\n",
    "recall = recall_score(all_targets, all_predictions)\n",
    "f1 = f1_score(all_targets, all_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef54d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ad599b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef4d931",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a83b6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f3867e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd260fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "259bed53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.0495\n",
      "Epoch [2/10], Loss: 1.3863\n",
      "Epoch [3/10], Loss: 1.0476\n",
      "Epoch [4/10], Loss: 1.6089\n",
      "Epoch [5/10], Loss: 0.9886\n",
      "Epoch [6/10], Loss: 1.1159\n",
      "Epoch [7/10], Loss: 1.3162\n",
      "Epoch [8/10], Loss: 1.4783\n",
      "Epoch [9/10], Loss: 1.4631\n",
      "Epoch [10/10], Loss: 1.1565\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define a simple linear model\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Example usage:\n",
    "# Define input size and output size\n",
    "input_size = 100  # Example input size\n",
    "output_size = 1    # Example output size\n",
    "\n",
    "# Initialize the model\n",
    "model = LinearModel(input_size, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Example loss function (Mean Squared Error)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)  # Example optimizer (Stochastic Gradient Descent)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    # Assuming inputs and targets are tensors (replace with your actual data)\n",
    "    inputs = torch.randn(32, input_size)  # Example input tensor (batch_size=32)\n",
    "    targets = torch.randn(32, output_size)  # Example target tensor (batch_size=32)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    \n",
    "    # Compute loss\n",
    "    loss = criterion(outputs, targets)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b12e20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060619bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1004/1413161639.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Iterate over validation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming you have a validation dataset 'val_loader' and model 'model' defined\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Initialize lists to store predictions and ground truth labels\n",
    "all_predictions = []\n",
    "all_targets = []\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Iterate over validation dataset\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Convert outputs to binary predictions (for binary classification)\n",
    "        predictions = (outputs > 0.5).float()  # Assuming sigmoid activation\n",
    "        \n",
    "        # Append predictions and targets to lists\n",
    "        all_predictions.extend(predictions.numpy().flatten())\n",
    "        all_targets.extend(targets.numpy().flatten())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_targets = np.array(all_targets)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(all_targets, all_predictions)\n",
    "\n",
    "# Compute precision, recall, and F1-score\n",
    "precision = precision_score(all_targets, all_predictions)\n",
    "recall = recall_score(all_targets, all_predictions)\n",
    "f1 = f1_score(all_targets, all_predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32fe8e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "189192d8",
   "metadata": {},
   "source": [
    "final?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9706809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a dataset named 'all_crema'\n",
    "# all_crema should be an instance of a PyTorch Dataset subclass\n",
    "\n",
    "# Define the percentage of data to be used for validation (e.g., 20%)\n",
    "val_split = 0.2\n",
    "\n",
    "# Calculate the size of the validation set\n",
    "val_size = int(val_split * len(all_crema))\n",
    "\n",
    "# Calculate the size of the training set\n",
    "train_size = len(all_crema) - val_size\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_dataset, val_dataset = random_split(all_crema, [train_size, val_size])\n",
    "\n",
    "# Define batch size for training and validation DataLoaders\n",
    "batch_size = 32  # Adjust as needed\n",
    "\n",
    "# Create DataLoaders for training and validation datasets\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    for inputs, targets in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Convert outputs to binary predictions (for binary classification)\n",
    "            predictions = (outputs > 0.5).float()  # Assuming sigmoid activation\n",
    "            \n",
    "            # Append predictions and targets to lists\n",
    "            all_predictions.extend(predictions.numpy().flatten())\n",
    "            all_targets.extend(targets.numpy().flatten())\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    all_predictions = np.array(all_predictions)\n",
    "    all_targets = np.array(all_targets)\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    precision = precision_score(all_targets, all_predictions)\n",
    "    recall = recall_score(all_targets, all_predictions)\n",
    "    f1 = f1_score(all_targets, all_predictions)\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e17e0da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34ee888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb732b0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b0c83b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4a19cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e278912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
